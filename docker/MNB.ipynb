{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12dfaa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re, nltk, string\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.utils import np_utils\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ec76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_word_frequency_word2vec = 5\n",
    "embed_size_word2vec = 200\n",
    "context_window_word2vec = 5\n",
    "\n",
    "numCV = 10\n",
    "max_sentence_len = 50\n",
    "min_sentence_length = 15\n",
    "rankK = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb565aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('classifier_data_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add44ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df.groupby('owner')['owner'].filter(lambda x: len(x) >= 500)\n",
    "f = df[df['owner'].isin(filtered)]\n",
    "df = f\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()\n",
    "len(f['owner'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.description\n",
    "y = df.owner\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01570a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = []\n",
    "train_owner = []\n",
    "test_data = []\n",
    "test_owner = []\n",
    "\n",
    "all_data_unfiltered = []\n",
    "\n",
    "def purge_string(text):\n",
    "    current_desc = text.replace('\\r', ' ')    \n",
    "    current_desc = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', current_desc)    \n",
    "    start_loc = current_desc.find(\"Stack trace:\")\n",
    "    current_desc = current_desc[:start_loc]    \n",
    "    current_desc = re.sub(r'(\\w+)0x\\w+', '', current_desc)\n",
    "    current_desc = current_desc.lower()\n",
    "    current_desc_tokens = nltk.word_tokenize(current_desc)\n",
    "    current_desc_filter = [word.strip(string.punctuation) for word in current_desc_tokens]\n",
    "    current_data = current_desc_filter\n",
    "    return current_data\n",
    "\n",
    "for item in X_train:\n",
    "    current_data = purge_string(item)\n",
    "    all_data_unfiltered.append(current_data)     \n",
    "    train_data.append(filter(None, current_data)) \n",
    "\n",
    "for item in y_train:\n",
    "    train_owner.append(item)\n",
    "    \n",
    "for item in X_test:\n",
    "    current_data = purge_string(item)\n",
    "    test_data.append(filter(None, current_data)) \n",
    "\n",
    "for item in y_test:\n",
    "    test_owner.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ff5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_data length = \"+str(len(train_data)))\n",
    "print(\"train_owner length = \"+str(len(train_owner)))\n",
    "print(\"test_data length = \"+str(len(test_data)))\n",
    "print(\"test_owner length = \"+str(len(test_owner)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f773719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = word2vec.Word2Vec(min_count=min_word_frequency_word2vec, vector_size=embed_size_word2vec, window=context_window_word2vec)\n",
    "model.init_sims(replace=True)\n",
    "model.build_vocab(all_data_unfiltered, progress_per=100000)\n",
    "vocabulary = model.wv.key_to_index\n",
    "vocab_size = len(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94cf2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c827fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train_data = []    \n",
    "updated_train_data_length = []    \n",
    "updated_train_owner = []\n",
    "final_test_data = []\n",
    "final_test_owner = []\n",
    "for j, item in enumerate(train_data):\n",
    "    current_train_filter = [word for word in item if word in vocabulary]\n",
    "    if len(current_train_filter)>=min_sentence_length:  \n",
    "      updated_train_data.append(current_train_filter)\n",
    "      updated_train_owner.append(train_owner[j])  \n",
    "      \n",
    "for j, item in enumerate(test_data):\n",
    "    current_test_filter = [word for word in item if word in vocabulary]  \n",
    "    if len(current_test_filter)>=min_sentence_length:\n",
    "      final_test_data.append(current_test_filter)    \t  \n",
    "      final_test_owner.append(test_owner[j]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7631420",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train_label = list(set(updated_train_owner))\n",
    "classes = np.array(unique_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty(shape=[len(updated_train_data), max_sentence_len, embed_size_word2vec], dtype='float32')\n",
    "Y_train = np.empty(shape=[len(updated_train_owner),1], dtype='int32')\n",
    "\n",
    "for j, curr_row in enumerate(updated_train_data):\n",
    "    sequence_cnt = 0         \n",
    "    for item in curr_row:\n",
    "        if item in vocabulary:\n",
    "            X_train[j, sequence_cnt, :] = model.wv[item] \n",
    "            sequence_cnt = sequence_cnt + 1                \n",
    "            if sequence_cnt == max_sentence_len-1:\n",
    "                    break                \n",
    "    for k in range(sequence_cnt, max_sentence_len):\n",
    "        X_train[j, k, :] = np.zeros((1,embed_size_word2vec))        \n",
    "    Y_train[j,0] = unique_train_label.index(updated_train_owner[j])\n",
    "\n",
    "X_test = np.empty(shape=[len(final_test_data), max_sentence_len, embed_size_word2vec], dtype='float32')\n",
    "Y_test = np.empty(shape=[len(final_test_owner),1], dtype='int32')\n",
    "\n",
    "for j, curr_row in enumerate(final_test_data):\n",
    "    sequence_cnt = 0          \n",
    "    for item in curr_row:\n",
    "        if item in vocabulary:\n",
    "            X_test[j, sequence_cnt, :] = model.wv[item] \n",
    "            sequence_cnt = sequence_cnt + 1                \n",
    "            if sequence_cnt == max_sentence_len-1:\n",
    "                break                \n",
    "    for k in range(sequence_cnt, max_sentence_len):\n",
    "        X_test[j, k, :] = np.zeros((1,embed_size_word2vec))        \n",
    "    Y_test[j,0] = unique_train_label.index(final_test_owner[j])\n",
    "\n",
    "y_train = np_utils.to_categorical(Y_train, len(unique_train_label))\n",
    "y_test = np_utils.to_categorical(Y_test, len(unique_train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for item in updated_train_data:\n",
    "    train_data.append(' '.join(item))\n",
    "\n",
    "test_data = []\n",
    "for item in final_test_data:\n",
    "    test_data.append(' '.join(item))\n",
    "\n",
    "vocab_data = []\n",
    "for item in vocabulary:\n",
    "    vocab_data.append(item)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "count_vect = CountVectorizer(min_df=1, vocabulary= vocab_data,dtype=np.int32)\n",
    "\n",
    "train_counts = count_vect.fit_transform(train_data)       \n",
    "train_feats = tfidf_transformer.fit_transform(train_counts)\n",
    "print (train_feats.shape)\n",
    "\n",
    "test_counts = count_vect.transform(test_data)\n",
    "test_feats = tfidf_transformer.transform(test_counts)\n",
    "print (test_feats.shape)\n",
    "print (\"=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa03871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0758991",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.fit(train_data)\n",
    "tfidf_transformer.fit(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7139c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(count_vect, open(\"count_vect.pickel\", \"wb\"))\n",
    "pickle.dump(tfidf_transformer, open(\"tfidf_transformer.pickel\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierModel = MultinomialNB(alpha=0.01)        \n",
    "classifierModel = OneVsRestClassifier(classifierModel).fit(train_feats, updated_train_owner)\n",
    "predict = classifierModel.predict_proba(test_feats)  \n",
    "classes = classifierModel.classes_  \n",
    "\n",
    "accuracy = []\n",
    "sortedIndices = []\n",
    "pred_classes = []\n",
    "for ll in predict:\n",
    "    sortedIndices.append(sorted(range(len(ll)), key=lambda ii: ll[ii], reverse=True))\n",
    "for k in range(1, rankK+1):\n",
    "    id = 0\n",
    "    trueNum = 0\n",
    "    for sortedInd in sortedIndices:            \n",
    "        if final_test_owner[id] in classes[sortedInd[:k]]:\n",
    "            trueNum += 1\n",
    "            pred_classes.append(classes[sortedInd[:k]])\n",
    "        id += 1\n",
    "    accuracy.append((float(trueNum) / len(predict)) * 100)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c203ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifierModel, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd5e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_owner[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def predict(bug_desc):\n",
    "    t_data = []\n",
    "    t_data.append(bug_desc)\n",
    "    count_vect = pickle.load(open('count_vect.pickel','rb'))\n",
    "    tfidf_transformer = pickle.load(open('tfidf_transformer.pickel','rb'))\n",
    "    test_counts = count_vect.transform(t_data)\n",
    "    test_feats = tfidf_transformer.transform(test_counts)\n",
    "    rankK = 10\n",
    "    print (test_feats.shape)   \n",
    "    model = pickle.load(open('model.pkl','rb'))\n",
    "    predict = model.predict_proba(test_feats)  \n",
    "    classes = model.classes_  \n",
    "\n",
    "    accuracy = []\n",
    "    sortedIndices = []\n",
    "    pred_classes = []\n",
    "    for ll in predict:\n",
    "        sortedIndices.append(sorted(range(len(ll)), key=lambda ii: ll[ii], reverse=True))\n",
    "    for k in range(1, rankK+1):\n",
    "        id = 0\n",
    "        trueNum = 0\n",
    "        for sortedInd in sortedIndices:            \n",
    "            if final_test_owner[id] in classes[sortedInd[:k]]:\n",
    "                trueNum += 1\n",
    "                pred_classes.append(classes[sortedInd[:k]])\n",
    "            id += 1\n",
    "        accuracy.append((float(trueNum) / len(predict)) * 100)\n",
    "    print(accuracy)\n",
    "    print(pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_id = np.where(classes ==test_owner[index])\n",
    "print(test_owner[index])\n",
    "print(dev_id)\n",
    "print(classes[dev_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b08d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2003\n",
    "predict(test_data[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(count_vect, open(\"count_vect.pickel\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4bd30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf_transformer, open(\"tfidf_transformer.pickel\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dbc85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('model.pkl','rb'))\n",
    "len(model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89aa36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = test_data[2003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict(bug_desc):\n",
    "    t_data = []\n",
    "    t_data.append(bug_desc)\n",
    "    test_counts = count_vect.transform(t_data)\n",
    "    test_feats = tfidf_transformer.transform(test_counts)\n",
    "    rankK = 10\n",
    "    print (test_feats.shape)   \n",
    "    model = pickle.load(open('model.pkl','rb'))\n",
    "    predict = model.predict_proba(test_feats)  \n",
    "    classes = model.classes_  \n",
    "\n",
    "    accuracy = []\n",
    "    sortedIndices = []\n",
    "    pred_classes = []\n",
    "    for ll in predict:\n",
    "        sortedIndices.append(sorted(range(len(ll)), key=lambda ii: ll[ii], reverse=True))\n",
    "    for k in range(1, rankK+1):\n",
    "        id = 0\n",
    "        trueNum = 0\n",
    "        for sortedInd in sortedIndices:            \n",
    "            if classes[id] in classes[sortedInd[:k]]:\n",
    "                trueNum += 1\n",
    "                pred_classes.append(classes[sortedInd[:k]])\n",
    "            id += 1\n",
    "        accuracy.append((float(trueNum) / len(predict)) * 100)\n",
    "    print(accuracy)\n",
    "    print(pred_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa2815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
